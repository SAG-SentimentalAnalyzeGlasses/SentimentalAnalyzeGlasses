package com.example.sentimentanalyzer;

import static android.Manifest.permission.CAMERA;
import static android.Manifest.permission.RECORD_AUDIO;

import android.annotation.TargetApi;
import android.app.Activity;
import android.content.BroadcastReceiver;
import android.content.Context;
import android.content.Intent;
import android.content.pm.PackageManager;
import android.graphics.Color;
import android.hardware.usb.UsbDevice;
import android.hardware.usb.UsbManager;
import android.os.Build;
import android.os.Bundle;
import android.os.SystemClock;
import android.speech.RecognitionListener;
import android.speech.RecognizerIntent;
import android.speech.SpeechRecognizer;
import android.util.Log;
import android.view.SurfaceView;
import android.view.View;
import android.view.WindowManager;
import android.widget.Button;
import android.widget.EditText;
import android.widget.ImageView;
import android.widget.Toast;

import androidx.appcompat.app.AppCompatActivity;

import com.github.mikephil.charting.charts.LineChart;
import com.github.mikephil.charting.components.AxisBase;
import com.github.mikephil.charting.components.Description;
import com.github.mikephil.charting.components.Legend;
import com.github.mikephil.charting.components.XAxis;
import com.github.mikephil.charting.components.YAxis;
import com.github.mikephil.charting.data.Entry;
import com.github.mikephil.charting.data.LineData;
import com.github.mikephil.charting.data.LineDataSet;
import com.github.mikephil.charting.formatter.IAxisValueFormatter;
import com.github.mikephil.charting.formatter.ValueFormatter;
import com.github.mikephil.charting.interfaces.datasets.ILineDataSet;

import org.opencv.android.BaseLoaderCallback;
import org.opencv.android.CameraBridgeViewBase;
import org.opencv.android.LoaderCallbackInterface;
import org.opencv.android.OpenCVLoader;
import org.opencv.core.CvType;
import org.opencv.core.Mat;

import java.io.IOException;
import java.text.DecimalFormat;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Locale;

public class CameraActivity extends AppCompatActivity {
    private static final int CAMERA_PERMISSION_REQUEST_CODE = 200;
    private static final int RECORD_AUDIO_PERMISSION_REQUEST_CODE = 201;
    private static String LOGTAG = "OpenCV_Log";
    private facialExpressionRecognition facialExpressionRecognition;
    private Mat mRgba;
    private Mat mGray;
    private boolean recording = false;
    private ArrayList<Float> faceRecognitionResult = new ArrayList<Float>();

    private Intent intent;
    private CameraBridgeViewBase mOpenCvCameraView;
    private EditText editText;
    private ImageView imageView;
    private Button button;
    private SpeechRecognizer mRecognizer = SpeechRecognizer.createSpeechRecognizer(CameraActivity.this); // ÏÉà SpeechRecognizer Î•º ÎßåÎìúÎäî Ìå©ÌÜ†Î¶¨ Î©îÏÑúÎìú
    private BackgroundThread mThread;

    //Graph
    private LineChart chart;

    /*usb camera*/
//    UsbDevice usbDevice = (UsbDevice) intent.getParcelableExtra(UsbManager.EXTRA_DEVICE);

    /*Í∏∞Í∏∞ Ïó¥Í±∞*/
//    UsbManager manager = (UsbManager) getSystemService(Context.USB_SERVICE);
//
//    HashMap<String, UsbDevice> deviceList = manager.getDeviceList();
//    UsbDevice device = deviceList.get("deviceName");
//
//
//    Iterator<UsbDevice> deviceIterator = deviceList.values().iterator();
//    while(deviceIterator.hasNext()){
//        UsbDevice device = deviceIterator.next();
//        //your code
//    }


    /*ÏóëÏÑ∏Ïä§ Í∂åÌïú Îü∞ÌÉÄÏûÑ*/
    private static final String ACTION_USB_PERMISSION =
            "com.android.example.USB_PERMISSION";
    private final BroadcastReceiver usbReceiver = new BroadcastReceiver() {

        public void onReceive(Context context, Intent intent) {
            String action = intent.getAction();
            if (ACTION_USB_PERMISSION.equals(action)) {
                synchronized (this) {
                    UsbDevice device = (UsbDevice)intent.getParcelableExtra(UsbManager.EXTRA_DEVICE);

                    if (intent.getBooleanExtra(UsbManager.EXTRA_PERMISSION_GRANTED, false)) {
                        if(device != null){
                            //call method to set up device communication
                        }
                    }
                    else {
                        Log.v(LOGTAG, "permission denied for device " + device);
                    }
                }
            }
        }
    };



    private BaseLoaderCallback mLoaderCallback = new BaseLoaderCallback(this) {
        @Override
        public void onManagerConnected(int status) {
            switch (status) {
                case LoaderCallbackInterface.SUCCESS: {
                    Log.v(LOGTAG, "OpenCV Loaded");
                    mOpenCvCameraView.enableView();
                } break;
                default:
                {
                    super.onManagerConnected(status);
                } break;
            }
        }
    };

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_camera);
        getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);
        getSupportActionBar().setIcon(R.drawable.sag);
        getSupportActionBar().setDisplayUseLogoEnabled(true);
        getSupportActionBar().setDisplayShowHomeEnabled(true);

//        boolean havePermission = true;
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {
//            if (checkSelfPermission(CAMERA) != PackageManager.PERMISSION_GRANTED) {
                requestPermissions(new String[]{CAMERA}, CAMERA_PERMISSION_REQUEST_CODE);
//                havePermission = false;
//            }
//            if (checkSelfPermission(RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) {
//                requestPermissions(new String[]{RECORD_AUDIO}, RECORD_AUDIO_PERMISSION_REQUEST_CODE);
//            }
        }
//        if (havePermission) {
//            onCameraPermissionGranted();
//        }

//        // ÏïàÎìúÎ°úÏù¥Îìú Î≤ÑÏ†ÑÏù¥ 6.0 Ïù¥ÏÉÅ
//        if(Build.VERSION.SDK_INT >= 23){
//            //Ïù∏ÌÑ∞ÎÑ∑Ïù¥ÎÇò ÎÖπÏùå Í∂åÌïúÏù¥ ÏóÜÏúºÎ©¥ Í∂åÌïú ÏöîÏ≤≠
//            if (ContextCompat.checkSelfPermission(this, Manifest.permission.INTERNET) == PackageManager.PERMISSION_DENIED
//                    || ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) == PackageManager.PERMISSION_DENIED
//                    || ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA) == PackageManager.PERMISSION_DENIED)
//                ActivityCompat.requestPermissions(this, new String[]{Manifest.permission.INTERNET, Manifest.permission.RECORD_AUDIO, Manifest.permission.CAMERA},PERMISSION);
//        }

        /*usb Ïπ¥Î©îÎùº*/
//        UsbManager usbManager = (UsbManager) getSystemService(Context.USB_SERVICE);
//        private static final String ACTION_USB_PERMISSION =
//                "com.android.example.USB_PERMISSION";
//
//        permissionIntent = PendingIntent.getBroadcast(this, 0, new Intent(ACTION_USB_PERMISSION), 0);
//        IntentFilter filter = new IntentFilter(ACTION_USB_PERMISSION);
//        registerReceiver(usbReceiver, filter);


        mOpenCvCameraView = (CameraBridgeViewBase) findViewById(R.id.opencv_surface_view);
        editText = findViewById(R.id.textResult);
        imageView = findViewById(R.id.imageView);
        button = findViewById(R.id.recordBtn);
//        mOpenCvCameraView.setCameraIndex(CameraBridgeViewBase.CAMERA_ID_FRONT);
        mOpenCvCameraView.setVisibility(SurfaceView.VISIBLE);
        mOpenCvCameraView.setCvCameraViewListener(cvCameraViewListener);
        mRecognizer.setRecognitionListener(listener); // Î¶¨Ïä§ÎÑà ÏÑ§Ï†ï
        try {
            int inputSize = 48;
            facialExpressionRecognition = new facialExpressionRecognition(getAssets(), CameraActivity.this, "model300.tflite", inputSize);
        }
        catch (IOException e) {
            e.printStackTrace();
            Log.d("CameraActivity", "Model is not loaded");
        }

        // RecognizerIntent ÏÉùÏÑ±
        intent = new Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH);
        intent.putExtra(RecognizerIntent.EXTRA_CALLING_PACKAGE,getPackageName()); // Ïó¨Î∂ÑÏùò ÌÇ§
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP) {
            intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault().toLanguageTag()); // Ïñ∏Ïñ¥ ÏÑ§Ï†ï
        }

        //Í∞êÏ†ï Ïù¥Î™®ÏßÄ Î≥ÄÍ≤Ω


        // Î≤ÑÌäº ÌÅ¥Î¶≠ Ïãú Í∞ùÏ≤¥Ïóê ContextÏôÄ listenerÎ•º Ìï†Îãπ
        button.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                if (!recording) {   //ÎÖπÏùå ÏãúÏûë
                    mRecognizer.startListening(intent); // Îì£Í∏∞ ÏãúÏûë

                    recording = true;
                    button.setText("Stop");
                    // ÌôîÎ©¥ ÏºúÏßê Ïú†ÏßÄ
                    getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);


                    editText.setText("");
                    faceRecognitionResult.clear();
                    mThread = new BackgroundThread();
                    mThread.start();
                } else {  //Ïù¥ÎØ∏ ÎÖπÏùå Ï§ëÏù¥Î©¥ ÎÖπÏùå Ï§ëÏßÄ
                    mRecognizer.cancel();
                    StopRecord();

                    mThread.interrupt(); // stop UI update
                }
            }
        });

        chart = (LineChart) findViewById(R.id.LineChart);
        chart.setDrawGridBackground(true);
        chart.setBackgroundColor(getResources().getColor(R.color.sag_green));
        chart.setGridBackgroundColor(getResources().getColor(R.color.sag_green));
        // description text
        chart.getDescription().setEnabled(true);
        Description des = chart.getDescription();
        des.setEnabled(true);
        des.setText("Emotion");
        des.setTextSize(15f);
        des.setTextColor(getResources().getColor(R.color.teal_200));


        // touch gestures (false-ÎπÑÌôúÏÑ±Ìôî)
        chart.setTouchEnabled(false);

        // scaling and dragging (false-ÎπÑÌôúÏÑ±Ìôî)
        chart.setDragEnabled(true);
        chart.setScaleEnabled(true);

        //auto scale
        chart.setAutoScaleMinMaxEnabled(false);

        // if disabled, scaling can be done on x- and y-axis separately
        chart.setPinchZoom(true);

        //XÏ∂ï
        XAxis x1 = chart.getXAxis();
        x1.setDrawGridLines(false);
        x1.setDrawAxisLine(false);
        x1.setTextColor(getResources().getColor(R.color.sag_green));
        x1.setTextSize(1f);
        x1.setAvoidFirstLastClipping(true);

        x1.setEnabled(true);

        //Legend
        Legend l = chart.getLegend();
        l.setEnabled(true);
        l.setFormSize(10f); // set the size of the legend forms/shapes
        l.setTextSize(12f);
        l.setTextColor(getResources().getColor(R.color.teal_200));

        //YÏ∂ï
        YAxis leftAxis = chart.getAxisLeft();
//        leftAxis.setValueFormatter(new MyYAxisValueFormatter());
        leftAxis.setValueFormatter(new ValueFormatter() {
            @Override
            public String getFormattedValue(float value) {
                if (value >= 0 & value < 1.5) {
                    return "Surpriseüò≤";
                } else if (value >= 0.5 & value < 1.5) {
                    return "Fearüò®";
                } else if (value >= 1.5 & value < 2.5) {
                    return "Angryüò†";
                } else if (value >= 2.5 & value < 3.5) {
                    return "Neutralüòê";
                } else if (value >= 3.5 & value < 4.5) {
                    return "Sadüò¢";
                } else if (value >= 4.5 & value < 5.5) {
                    return "Disgustüò´";
                } else {
                    return "HappyüòÑ";
                }

//                if (value < 2.0) {
//                    return "üò≠";
//                } else if (value >= 2.0 & value < 3.0) {
//                    return "-_-üò≠";
//                } else {
//                    return "^o^üò≠";
//                }
            }
        });
        leftAxis.setGranularity(1.2f);
        leftAxis.setEnabled(true);
        leftAxis.setTextColor(Color.BLACK);
        leftAxis.setTextSize(10f);
        leftAxis.setDrawGridLines(true);
        leftAxis.setGridLineWidth(0.5f);
        leftAxis.setGridColor(getResources().getColor(R.color.sag_white));

        YAxis rightAxis = chart.getAxisRight();
        rightAxis.setEnabled(false);

        // don't forget to refresh the drawing
        chart.invalidate();

    }
    private void addEntry(double num1, double num2){
        LineData data = chart.getData();
//        LineData data1 = chart.getData();
//        Log.v(LOGTAG, "chartData: " + data);
//        Log.v(LOGTAG, "chartData:1 " + data1);

        if (data == null) {
            data = new LineData();
            chart.setData(data);
        }
//        if (data1 == null) {
//            data1 = new LineData();
//            chart.setData(data1);
//        }

        ILineDataSet set = data.getDataSetByIndex(0);
        ILineDataSet set1 = data.getDataSetByIndex(1);

        if (set == null) {
            set = createSet(getResources().getColor(R.color.sag_blue));
            data.addDataSet(set);
        }
        if (set1 == null) {
            set1 = createSet(getResources().getColor(R.color.sag_ginblue));
            data.addDataSet(set1);
        }

        data.addEntry(new Entry((float)set.getEntryCount(), (float)num1), 0);
        if(num2 != -1) {
            data.addEntry(new Entry((float) set1.getEntryCount(), (float) num2), 1);
        }
        data.notifyDataChanged();
//        data1.notifyDataChanged();

        // let the chart know it's data has changed
        chart.notifyDataSetChanged();

        chart.setVisibleXRangeMaximum(30);
        // this automatically refreshes the chart (calls invalidate())
        chart.moveViewTo(data.getEntryCount(), 50f, YAxis.AxisDependency.LEFT);
    }

    private LineDataSet createSet(int color) {
        LineDataSet set = new LineDataSet(null, "");
        set.setLineWidth(2f);
//        R.color.sag_blue
//        R.color.sag_ginblue
        set.setCircleRadius(2.5f);
        set.setDrawCircleHole(true);
        set.setCircleColor(color);
        set.setDrawValues(false);
        set.setColor(color);
        set.setMode(LineDataSet.Mode.CUBIC_BEZIER);
//        set.setDrawCircles(false);

        set.setHighLightColor(Color.rgb(190, 190, 190));

        return set;
    }

//    private LineDataSet createSet1() {
//        LineDataSet set = new LineDataSet(null, "");
//        set.setLineWidth(2f);
//
//        set.setCircleRadius(2.5f);
//        set.setDrawCircleHole(true);
//        set.setCircleColor(getResources().getColor(R.color.sag_ginblue));
//        set.setDrawValues(false);
//        set.setColor(getResources().getColor(R.color.sag_blue));
//        set.setMode(LineDataSet.Mode.CUBIC_BEZIER);
////        set.setDrawCircles(false);
//
//        set.setHighLightColor(Color.rgb(190, 190, 190));
//
//        return set;
//    }

    private void StopRecord() {
        recording = false;
        button.setText("Analyze Emotion");
        // ÌôîÎ©¥ ÏºúÏßê Ïú†ÏßÄ ÎÅÑÍ∏∞
        getWindow().clearFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);
    }

    private RecognitionListener listener = new RecognitionListener() {
        @Override
        public void onReadyForSpeech(Bundle params) {
            // ÎßêÌïòÍ∏∞ ÏãúÏûëÌï† Ï§ÄÎπÑÍ∞ÄÎêòÎ©¥ Ìò∏Ï∂ú
        }

        @Override
        public void onBeginningOfSpeech() {
            // ÎßêÌïòÍ∏∞ ÏãúÏûëÌñàÏùÑ Îïå Ìò∏Ï∂ú
        }

        @Override
        public void onRmsChanged(float rmsdB) {
            // ÏûÖÎ†•Î∞õÎäî ÏÜåÎ¶¨Ïùò ÌÅ¨Í∏∞Î•º ÏïåÎ†§Ï§å
        }

        @Override
        public void onBufferReceived(byte[] buffer) {
            // ÎßêÏùÑ ÏãúÏûëÌïòÍ≥† Ïù∏ÏãùÏù¥ Îêú Îã®Ïñ¥Î•º bufferÏóê Îã¥Ïùå
        }

        @Override
        public void onEndOfSpeech() {
            // ÎßêÌïòÍ∏∞Î•º Ï§ëÏßÄÌïòÎ©¥ Ìò∏Ï∂ú
        }

        @Override
        public void onError(int error) {
            // ÎÑ§Ìä∏ÏõåÌÅ¨ ÎòêÎäî Ïù∏Ïãù Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏùÑ Îïå Ìò∏Ï∂ú
            String message;

            switch (error) {
                case SpeechRecognizer.ERROR_AUDIO:
                    message = "Ïò§ÎîîÏò§ ÏóêÎü¨";
                    break;
                case SpeechRecognizer.ERROR_CLIENT:
                    message = "";
                    break;
                case SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS:
                    message = "ÌçºÎØ∏ÏÖò ÏóÜÏùå";
                    break;
                case SpeechRecognizer.ERROR_NETWORK:
                    message = "ÎÑ§Ìä∏ÏõåÌÅ¨ ÏóêÎü¨";
                    break;
                case SpeechRecognizer.ERROR_NETWORK_TIMEOUT:
                    message = "ÎÑ§Ìä∏Ïõç ÌÉÄÏûÑÏïÑÏõÉ";
                    break;
                case SpeechRecognizer.ERROR_NO_MATCH:
                    Toast.makeText(getApplicationContext(), "Ïù∏ÏãùÌï† Ïàò ÏóÜÎäî ÏùåÏÑ± ÎòêÎäî ÏùåÏÑ± ÏûÖÎ†• ÎåÄÍ∏∞ Ï§ë",Toast.LENGTH_SHORT).show();
                    mRecognizer.startListening(intent);
                    return;
                case SpeechRecognizer.ERROR_RECOGNIZER_BUSY:
                    message = "RECOGNIZER Í∞Ä Î∞îÏÅ®";
                    break;
                case SpeechRecognizer.ERROR_SERVER:
                    message = "ÏÑúÎ≤ÑÍ∞Ä Ïù¥ÏÉÅÌï®";
                    break;
                case SpeechRecognizer.ERROR_SPEECH_TIMEOUT:
                    message = "ÎßêÌïòÎäî ÏãúÍ∞ÑÏ¥àÍ≥º";
                    break;
                case 12:
                    message = "Ïù∏ÏãùÍ∏∞Í∞Ä ÏßÄÏõêÌïòÏßÄ ÏïäÎäî Ïñ∏Ïñ¥";
                    break;
                default:
                    message = "Ïïå Ïàò ÏóÜÎäî Ïò§Î•òÏûÑ" + error;
                    break;
            }
            StopRecord();
            if(!message.equals(""))
                Toast.makeText(getApplicationContext(), "ÏóêÎü¨ Î∞úÏÉù : " + message,Toast.LENGTH_SHORT).show();
        }

        @Override
        public void onResults(Bundle results) {
            // Ïù∏Ïãù Í≤∞Í≥ºÍ∞Ä Ï§ÄÎπÑÎêòÎ©¥ Ìò∏Ï∂ú
            // ÎßêÏùÑ ÌïòÎ©¥ ArrayListÏóê Îã®Ïñ¥Î•º ÎÑ£Í≥† textViewÏóê Îã®Ïñ¥Î•º Ïù¥Ïñ¥Ï§å
            ArrayList<String> matches = results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION);
            String originText = editText.getText().toString();

            // Ïù∏Ïãù Í≤∞Í≥º
            String newText="";
            for(int i = 0; i < matches.size() ; i++){
                newText += matches.get(i);
            }

//            editText.setText(originText + newText + " ");	//Í∏∞Ï°¥Ïùò textÏóê Ïù∏Ïãù Í≤∞Í≥ºÎ•º Ïù¥Ïñ¥Î∂ôÏûÑ
            mRecognizer.startListening(intent);    //ÎÖπÏùåÎ≤ÑÌäºÏùÑ ÎàÑÎ•º ÎïåÍπåÏßÄ Í≥ÑÏÜç ÎÖπÏùåÌï¥Ïïº ÌïòÎØÄÎ°ú ÎÖπÏùå Ïû¨Í∞ú
        }

        @Override
        public void onPartialResults(Bundle partialResults) {
            // Î∂ÄÎ∂Ñ Ïù∏Ïãù Í≤∞Í≥ºÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏûàÏùÑ Îïå Ìò∏Ï∂ú
        }

        @Override
        public void onEvent(int eventType, Bundle params) {
            // Ìñ•ÌõÑ Ïù¥Î≤§Ìä∏Î•º Ï∂îÍ∞ÄÌïòÍ∏∞ ÏúÑÌï¥ ÏòàÏïΩ
        }
    };

    private CameraBridgeViewBase.CvCameraViewListener2 cvCameraViewListener = new CameraBridgeViewBase.CvCameraViewListener2() {
        @Override
        public void onCameraViewStarted(int width ,int height){
            mRgba=new Mat(height,width, CvType.CV_8UC4);
            mGray =new Mat(height,width,CvType.CV_8UC1);
        }

        @Override
        public void onCameraViewStopped() {

        }

        @Override
        public Mat onCameraFrame(CameraBridgeViewBase.CvCameraViewFrame inputFrame){
            mRgba=inputFrame.rgba();
            mGray=inputFrame.gray();

            if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {
                mRgba = facialExpressionRecognition.recognizeImage(mRgba);
            }
            return mRgba;

        }
    };

    @Override
    protected void onStart() {
        super.onStart();
    }

    protected List<?extends CameraBridgeViewBase> getCameraViewList() {
        return Collections.singletonList(mOpenCvCameraView);
    }

    protected void onCameraPermissionGranted() {
        List<? extends CameraBridgeViewBase> cameraViews = getCameraViewList();
        if (cameraViews == null) {
            return;
        }
        for (CameraBridgeViewBase cameraBridgeViewBase: cameraViews) {
            if (cameraBridgeViewBase != null) {
                cameraBridgeViewBase.setCameraPermissionGranted();
            }
        }
    }

    @Override
    protected void onResume() {
        super.onResume();
        if (OpenCVLoader.initDebug()){
            //if load success
            Log.d(LOGTAG,"Opencv initialization is done");
            mLoaderCallback.onManagerConnected(LoaderCallbackInterface.SUCCESS);
        }
        else{
            //if not loaded
            Log.d(LOGTAG,"Opencv is not loaded. try again");
            OpenCVLoader.initAsync(OpenCVLoader.OPENCV_VERSION_3_4_0,this,mLoaderCallback);
        }
    }

    @Override
    public void onPause() {
        super.onPause();
        if (mOpenCvCameraView !=null){
            mOpenCvCameraView.disableView();
        }
    }

    @Override
    public void onDestroy() {
        super.onDestroy();
        if (mOpenCvCameraView != null) {
            mOpenCvCameraView.disableView();
        }
    }

    @Override
    @TargetApi(Build.VERSION_CODES.M)
    public void onRequestPermissionsResult(int requestCode, String[] permissions, int[] grantResults) {
        if (requestCode == CAMERA_PERMISSION_REQUEST_CODE && grantResults.length > 0
                && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
            onCameraPermissionGranted();
        }
        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
    }


    // thread for update UI
    class BackgroundThread extends Thread {
        @Override
        public void run() {
            while(!Thread.currentThread().isInterrupted()) {
                runOnUiThread(new Runnable() {
                    @Override
                    public void run() {
                        float emotion_v = facialExpressionRecognition.get_emotion_value();

                        if (emotion_v == 0.0) {
                            faceRecognitionResult.clear();
                        } else {
                            faceRecognitionResult.add(facialExpressionRecognition.get_emotion_value());


                            if (faceRecognitionResult.size() > 5) {
                                float result_average = 0;
                                float result_averageper4s = -1;
                                for (int i = 0; i < faceRecognitionResult.size(); i++) {
                                    result_average += faceRecognitionResult.get(i);
                                }
                                result_average /= faceRecognitionResult.size();
                                addEntry(result_average, result_averageper4s);

                                //editText.setText(editText.getText() + "\n" + facialExpressionRecognition.get_emotion_text(result_average) + " " + result_average);

                                faceRecognitionResult.clear();
                            }
                        }
                    }
                });

                SystemClock.sleep(200);
            }
            faceRecognitionResult.clear();
        }
    }
}